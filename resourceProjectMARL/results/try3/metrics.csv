iteration,episode_reward_mean,episode_reward_min,episode_reward_max,episode_len_mean,fairness_gini,jain_fairness_index,resource_specialisation,agent_overlap,task_division,policy_divergence,entropy_coeff
1,36.386249999999734,6.3900000000000405,82.93499999999968,500.0,0.8455470607608766,0.8955141331174045,0.14552819865319866,0.0,0.14552819865319866,0.0,0.0067
2,46.47656249999972,6.3900000000000405,104.99999999999969,500.0,0.8468390153936134,0.8868699285095627,0.13198997183372185,0.0,0.13198997183372185,0.0,0.0034000000000000002
3,64.21249999999985,6.3900000000000405,405.9600000000022,500.0,0.8174217288884682,0.8562937489326424,0.1372749907569504,0.0,0.1372749907569504,0.0,9.99999999999994e-05
