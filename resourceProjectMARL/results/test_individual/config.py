# Auto-generated configuration file
# Do not edit manually

CONFIG = {   '_disable_action_flattening': False,
    '_disable_execution_plan_api': -1,
    '_disable_initialize_loss_from_dummy_batch': False,
    '_disable_preprocessor_api': False,
    '_dont_auto_sync_env_runner_states': False,
    '_enable_rl_module_api': -1,
    '_env_to_module_connector': None,
    '_fake_gpus': False,
    '_is_atari': None,
    '_learner_class': None,
    '_learner_connector': None,
    '_model_config': {},
    '_module_to_env_connector': None,
    '_per_module_overrides': {},
    '_prior_exploration_config': None,
    '_rl_module_spec': None,
    '_tf_policy_handles_more_than_one_loss': False,
    '_torch_grad_scaler_class': None,
    '_torch_lr_scheduler_classes': None,
    '_train_batch_size_per_learner': None,
    '_use_msgpack_checkpoints': False,
    '_validate_config': True,
    'action_mask_key': 'action_mask',
    'action_space': None,
    'actions_in_input_normalized': False,
    'add_default_connectors_to_env_to_module_pipeline': True,
    'add_default_connectors_to_learner_pipeline': True,
    'add_default_connectors_to_module_to_env_pipeline': True,
    'algorithm_config_overrides_per_module': {},
    'always_attach_evaluation_results': -1,
    'auto_wrap_old_gym_envs': -1,
    'batch_mode': 'truncate_episodes',
    'callbacks': "<class 'ray.rllib.callbacks.callbacks.RLlibCallback'>",
    'callbacks_class': "<class '__main__.train_main.<locals>.CompleteTrainingCallback'>",
    'callbacks_on_algorithm_init': None,
    'callbacks_on_checkpoint_loaded': None,
    'callbacks_on_env_runners_recreated': None,
    'callbacks_on_environment_created': None,
    'callbacks_on_episode_created': None,
    'callbacks_on_episode_end': None,
    'callbacks_on_episode_start': None,
    'callbacks_on_episode_step': None,
    'callbacks_on_evaluate_end': None,
    'callbacks_on_evaluate_start': None,
    'callbacks_on_sample_end': None,
    'callbacks_on_train_result': None,
    'checkpoint_trainable_policies_only': False,
    'clip_actions': False,
    'clip_param': 0.2,
    'clip_rewards': None,
    'compress_observations': False,
    'count_steps_by': 'env_steps',
    'create_env_on_driver': False,
    'custom_async_evaluation_function': -1,
    'custom_eval_function': None,
    'custom_resources_per_env_runner': {},
    'dataset_num_iters_per_learner': None,
    'delay_between_env_runner_restarts_s': 60.0,
    'disable_env_checking': False,
    'eager_max_retraces': 20,
    'eager_tracing': True,
    'enable_async_evaluation': -1,
    'enable_connectors': -1,
    'enable_env_runner_and_connector_v2': False,
    'enable_rl_module_and_learner': False,
    'enable_tf1_exec_eagerly': False,
    'entropy_coeff': 0.01,
    'entropy_coeff_schedule': None,
    'env': 'ResourceCollectionEnv',
    'env_config': {   'gridSize': (12, 12),
                      'hybridRewardMix': 0.5,
                      'numAgents': 4,
                      'output_dir': 'results/test_individual',
                      'renderMode': None,
                      'rewardType': 'individual',
                      'seed': 879768,
                      'use_flattened_obs': True},
    'env_runner_cls': None,
    'env_runner_health_probe_timeout_s': 30.0,
    'env_runner_restore_timeout_s': 1800.0,
    'env_task_fn': -1,
    'episode_lookback_horizon': 1,
    'episodes_to_numpy': True,
    'evaluation_config': {   'env_config': {   'gridSize': (12, 12),
                                               'hybridRewardMix': 0.5,
                                               'numAgents': 4,
                                               'output_dir': 'results/test_individual',
                                               'renderMode': None,
                                               'rewardType': 'individual',
                                               'seed': 879768,
                                               'use_flattened_obs': True},
                             'explore': False},
    'evaluation_duration': 10,
    'evaluation_duration_unit': 'episodes',
    'evaluation_force_reset_envs_before_iteration': True,
    'evaluation_interval': 5,
    'evaluation_num_env_runners': 1,
    'evaluation_num_workers': 1,
    'evaluation_parallel_to_training': False,
    'evaluation_sample_timeout_s': 120.0,
    'exploration_config': {'type': 'StochasticSampling'},
    'explore': True,
    'export_native_model_files': False,
    'extra_python_environs_for_driver': {},
    'extra_python_environs_for_worker': {},
    'fake_sampler': False,
    'framework': 'torch',
    'gamma': 0.99,
    'grad_clip': None,
    'grad_clip_by': 'global_norm',
    'gym_env_vectorize_mode': 'SYNC',
    'ignore_env_runner_failures': False,
    'in_evaluation': False,
    'input': 'sampler',
    'input_compress_columns': ['obs', 'new_obs'],
    'input_config': {},
    'input_filesystem': None,
    'input_filesystem_kwargs': {},
    'input_read_batch_size': None,
    'input_read_episodes': False,
    'input_read_method': 'read_parquet',
    'input_read_method_kwargs': {},
    'input_read_sample_batches': False,
    'input_read_schema': {},
    'input_spaces_jsonable': True,
    'iter_batches_kwargs': {},
    'keep_per_episode_custom_metrics': False,
    'kl_coeff': 0.2,
    'kl_target': 0.01,
    'lambda': 0.95,
    'lambda_': 0.95,
    'learner_config_dict': {},
    'local_gpu_idx': 0,
    'local_tf_session_args': {'inter_op_parallelism_threads': 8, 'intra_op_parallelism_threads': 8},
    'log_gradients': True,
    'log_level': 'WARN',
    'log_sys_usage': True,
    'logger_config': {   'logdir': 'results/test_individual\\tensorboard',
                         'type': 'ray.tune.logger.TBXLogger'},
    'logger_creator': None,
    'lr': 0.0003,
    'lr_schedule': None,
    'map_batches_kwargs': {},
    'materialize_data': False,
    'materialize_mapped_data': True,
    'max_num_env_runner_restarts': 1000,
    'max_requests_in_flight_per_aggregator_actor': 3,
    'max_requests_in_flight_per_env_runner': 1,
    'max_requests_in_flight_per_learner': 3,
    'metrics_episode_collection_timeout_s': 60.0,
    'metrics_num_episodes_for_smoothing': 100,
    'min_sample_timesteps_per_iteration': 0,
    'min_time_s_per_iteration': None,
    'min_train_timesteps_per_iteration': 0,
    'minibatch_size': 128,
    'model': {   'custom_model_config': {   'agent_view_radius': 5,
                                            'centralised_critic_model': 'CentralisedCriticNetwork',
                                            'hybrid_reward_mix': 0.5,
                                            'num_agents': 4,
                                            'partial_observability': True,
                                            'reward_type': 'individual',
                                            'use_attention': False,
                                            'use_centralised_critic': True},
                 'fcnet_activation': 'relu',
                 'fcnet_hiddens': [256, 256, 128]},
    'multiagent': {   'policies': {'shared_policy': (None, None, None, {})},
                      'policy_mapping_fn': '<function '
                                           'PPOPolicy._configureMAPPO.<locals>.policyMappingFn at '
                                           '0x0000025ABD851580>'},
    'normalize_actions': True,
    'num_aggregator_actors_per_learner': 0,
    'num_consecutive_env_runner_failures_tolerance': 100,
    'num_cpus_for_main_process': 1,
    'num_cpus_per_env_runner': 1,
    'num_cpus_per_learner': 'auto',
    'num_env_runners': 2,
    'num_envs_per_env_runner': 1,
    'num_epochs': 30,
    'num_gpus': 1,
    'num_gpus_per_env_runner': 0,
    'num_gpus_per_learner': 0,
    'num_learners': 0,
    'num_sgd_iter': 10,
    'num_workers': 8,
    'observation_filter': 'NoFilter',
    'observation_fn': None,
    'observation_space': None,
    'off_policy_estimation_methods': {},
    'offline_data_class': None,
    'offline_sampling': False,
    'ope_split_batch_by_episode': True,
    'optimizer': {},
    'output': None,
    'output_compress_columns': ['obs', 'new_obs'],
    'output_config': {},
    'output_filesystem': None,
    'output_filesystem_kwargs': {},
    'output_max_file_size': 67108864,
    'output_max_rows_per_file': None,
    'output_write_episodes': True,
    'output_write_method': 'write_parquet',
    'output_write_method_kwargs': {},
    'output_write_remaining_data': False,
    'placement_strategy': 'PACK',
    'policies': {'default_policy': (None, None, None, None)},
    'policies_to_train': None,
    'policy_map_cache': -1,
    'policy_map_capacity': 100,
    'policy_mapping_fn': '<function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at '
                         '0x0000025ABBABE480>',
    'policy_states_are_swappable': False,
    'postprocess_inputs': False,
    'prelearner_buffer_class': None,
    'prelearner_buffer_kwargs': {},
    'prelearner_class': None,
    'prelearner_module_synch_period': 10,
    'preprocessor_pref': 'deepmind',
    'remote_env_batch_wait_ms': 0,
    'remote_worker_envs': False,
    'render_env': False,
    'replay_sequence_length': None,
    'restart_failed_env_runners': True,
    'restart_failed_sub_environments': False,
    'rollout_fragment_length': 'auto',
    'sample_collector': '<class '
                        "'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>",
    'sample_timeout_s': 60.0,
    'sampler_perf_stats_ema_coef': None,
    'seed': 879768,
    'sgd_minibatch_size': 128,
    'shuffle_batch_per_epoch': True,
    'shuffle_buffer_size': 0,
    'simple_optimizer': -1,
    'sync_filters_on_rollout_workers_timeout_s': 10.0,
    'synchronize_filters': -1,
    'tf_session_args': {   'allow_soft_placement': True,
                           'device_count': {'CPU': 1},
                           'gpu_options': {'allow_growth': True},
                           'inter_op_parallelism_threads': 2,
                           'intra_op_parallelism_threads': 2,
                           'log_device_placement': False},
    'torch_compile_learner': False,
    'torch_compile_learner_dynamo_backend': 'inductor',
    'torch_compile_learner_dynamo_mode': None,
    'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>,
    'torch_compile_worker': False,
    'torch_compile_worker_dynamo_backend': 'onnxrt',
    'torch_compile_worker_dynamo_mode': None,
    'torch_ddp_kwargs': {},
    'torch_skip_nan_gradients': False,
    'train_batch_size': 4000,
    'update_worker_filter_stats': True,
    'use_critic': True,
    'use_gae': True,
    'use_kl_loss': True,
    'use_worker_filter_stats': True,
    'validate_env_runners_after_construction': True,
    'vf_clip_param': 10.0,
    'vf_loss_coeff': 0.5,
    'vf_share_layers': -1,
    'worker_cls': -1}

# Export the config for easy import
def getConfig():
    return CONFIG
